import time
from base_ctrl_js import BaseController
import glob
import threading
import queue
import numpy as np
import sounddevice as sd
import scipy.io.wavfile as wav
import whisper
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore")

SAMPLE_RATE = 16000
CHANNELS = 1
OUTPUT_FILE = "recorded_audio.wav"
recording = []

# Whisper ëª¨ë¸ì„ ì „ì—­ ë³€ìˆ˜ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ
print("ìŒì„± ì¸ì‹ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
whisper_model = whisper.load_model("tiny.en")

def audio_callback(indata, frames, time_info, status):
    recording.append(indata.copy())

def record_audio():
    global recording
    recording = []
    print("ğŸ¤ ìŒì„±ì„ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤... (Enterë¥¼ ëˆŒëŸ¬ ë…¹ìŒì„ ì¢…ë£Œí•˜ì„¸ìš”)")
    
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, callback=audio_callback):
        input()  # Enter í‚¤ë¥¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°
    
    audio_data = np.concatenate(recording, axis=0)
    wav.write(OUTPUT_FILE, SAMPLE_RATE, audio_data)

def transcribe_audio():
    result = whisper_model.transcribe(OUTPUT_FILE)
    return result["text"].strip().lower()

class TarsAIDriver:
    def __init__(self):
        # ì‹œë¦¬ì–¼ í¬íŠ¸ ì°¾ê¸° ë° BaseController ì´ˆê¸°í™”
        try:
            available_ports = glob.glob('/dev/ttyUSB*')
            if available_ports:
                port = available_ports[0]
                print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì–¼ í¬íŠ¸: {port}")
                self.base = BaseController(port, 115200)
            else:
                print("ì‹œë¦¬ì–¼ í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°€ìƒ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                self.base = BaseController("VIRTUAL", 115200)
        except Exception as e:
            print(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.base = BaseController("VIRTUAL", 115200)

        # ì œì–´ ê´€ë ¨ ë³€ìˆ˜
        self.running = True
        self.command_queue = queue.Queue()
        self.last_update_time = time.time()
        self.UPDATE_INTERVAL = 0.1  # 100ms ê°„ê²©ìœ¼ë¡œ ì œì–´ ëª…ë ¹ ì „ì†¡

        # ê¸°ë³¸ ì œì–´ íŒŒë¼ë¯¸í„°
        self.linear_speed = 0.0
        self.angular_speed = 0.0
        self.MAX_SPEED = 0.5
        self.MAX_STEER = 0.3

        # ìŒì„± ëª…ë ¹ ë§¤í•‘
        self.command_mapping = {
            'go': (0.3, 0.0),      # ì „ì§„
            'back': (-0.3, 0.0),   # í›„ì§„
            'left': (0.5, 0.3),    # ì¢ŒíšŒì „
            'right': (0.5, -0.3),  # ìš°íšŒì „
            'stop': (0.0, 0.0)     # ì •ì§€
        }

    def update_robot(self):
        """ë¡œë´‡ì˜ ì†ë„ì™€ ë°©í–¥ì„ ì—…ë°ì´íŠ¸"""
        self.base.base_velocity_ctrl(self.linear_speed, self.angular_speed)

    def set_velocity(self, linear_x, angular_z):
        """ì„ í˜• ì†ë„ì™€ ê°ì†ë„ ì„¤ì •"""
        # ì†ë„ ì œí•œ ì ìš©
        self.linear_speed = np.clip(linear_x, -self.MAX_SPEED, self.MAX_SPEED)
        self.angular_speed = np.clip(angular_z, -self.MAX_STEER, self.MAX_STEER)

    def stop(self):
        """ë¡œë´‡ ì •ì§€"""
        self.linear_speed = 0.0
        self.angular_speed = 0.0
        self.update_robot()

    def process_voice_command(self, command):
        """ìŒì„± ëª…ë ¹ ì²˜ë¦¬"""
        # ëª…ë ¹ì–´ í…ìŠ¤íŠ¸ ì •ë¦¬ (ì†Œë¬¸ì ë³€í™˜, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        command = command.lower().strip('!.,?')
        
        # ëª…ë ¹ì–´ ë§¤í•‘ì—ì„œ ê°€ì¥ ì˜ ë§¤ì¹­ë˜ëŠ” ëª…ë ¹ ì°¾ê¸°
        best_match = None
        for cmd in self.command_mapping.keys():
            if cmd in command:
                best_match = cmd
                break
        
        if best_match:
            linear, angular = self.command_mapping[best_match]
            self.set_velocity(linear, angular)
            print(f"ëª…ë ¹ ì‹¤í–‰: {best_match} (ì„ ì†ë„: {linear}, ê°ì†ë„: {angular})")
        else:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹: {command}")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´: go, back, left, right, stop")

    def run(self):
        """ë©”ì¸ ì œì–´ ë£¨í”„"""
        print("ìŒì„± ì œì–´ ëª¨ë“œ ì‹œì‘...")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´: go, back, left, right, stop")
        print("Enterë¥¼ ëˆŒëŸ¬ ìŒì„± ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        try:
            while self.running:
                user_input = input("\nğŸ”˜ [Enter]ë¥¼ ëˆŒëŸ¬ ìŒì„± ì…ë ¥ì„ ì‹œì‘í•˜ì„¸ìš” (ë˜ëŠ” 'quit' ì…ë ¥):").strip()
                
                if user_input.lower() == 'quit':
                    break
                
                if not user_input:
                    record_audio()
                    command = transcribe_audio()
                    print(f"\nğŸ‘¤ ìŒì„± ì…ë ¥: {command}")
                    self.process_voice_command(command)
                
                # ì£¼ê¸°ì ìœ¼ë¡œ ë¡œë´‡ ìƒíƒœ ì—…ë°ì´íŠ¸
                current_time = time.time()
                if current_time - self.last_update_time >= self.UPDATE_INTERVAL:
                    self.update_robot()
                    self.last_update_time = current_time
                
                time.sleep(0.01)  # CPU ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°

        except KeyboardInterrupt:
            print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.stop()
            print("ìŒì„± ì œì–´ ëª¨ë“œ ì¢…ë£Œ")

if __name__ == "__main__":
    driver = TarsAIDriver()
    driver.run() 